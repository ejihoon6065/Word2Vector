{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "5.4.Sentiment Analysis.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ejihoon6065/-/blob/master/Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fk54oXIXKyUu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9402681f-7310-47ad-c4e4-c625dbe5dd9c"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUKrmZqaK5Jb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "bc069c85-6086-4f7d-8dbc-f4db44fcd070"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'5.4.Sentiment Analysis.ipynb'\t log\t   preprocessing  'Untitled Folder'\n",
            "'5.4.Sentiment Analysis.zip'\t log.zip   test.tsv\n",
            " data\t\t\t\t model\t   train.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkYizESTK74_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "29a5f88e-ac1c-44f9-b451-5fac9a221ef9"
      },
      "source": [
        "cd 5.4.Sentiment Analysis"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 20] Not a directory: '5.4.Sentiment Analysis.ipynb'\n",
            "/content/Sentiment Analysis\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7EEFXKPW8i5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1a012894-b9a4-4599-9746-05132d6317c2"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'/content/Sentiment Analysis'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sr7DljeNKR0z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "6cb74fbd-7999-484f-8ab8-b255279facfe"
      },
      "source": [
        "import pandas as pd\n",
        "from model.LSTM import LSTM_model\n",
        "from preprocessing.text_preprocessing import Sentences2LemmaWords\n",
        "from preprocessing.text_preprocessing import GetUnique\n",
        "from preprocessing.text_preprocessing import setTokenizer\n",
        "from preprocessing.text_preprocessing import LemmaWords2Seqeunces\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "import time\n",
        "from log.logger import Logger"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWn9XdbpKR03",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "outputId": "420aa0a2-dd2d-4621-afad-e2332675ef5e"
      },
      "source": [
        "folder_path = './data/'\n",
        "train = pd.read_csv('train.tsv', sep='\\t')\n",
        "test = pd.read_csv('test.tsv', sep='\\t')\n",
        "\n",
        "print('train data shape: ', train.shape)\n",
        "print('test data shape: ', test.shape)\n",
        "print('----------[train infomation]----------')\n",
        "print(train.info())\n",
        "print('----------[test infomation]----------')\n",
        "print(test.info())"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train data shape:  (156060, 4)\n",
            "test data shape:  (66292, 3)\n",
            "----------[train infomation]----------\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 156060 entries, 0 to 156059\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count   Dtype \n",
            "---  ------      --------------   ----- \n",
            " 0   PhraseId    156060 non-null  int64 \n",
            " 1   SentenceId  156060 non-null  int64 \n",
            " 2   Phrase      156060 non-null  object\n",
            " 3   Sentiment   156060 non-null  int64 \n",
            "dtypes: int64(3), object(1)\n",
            "memory usage: 4.8+ MB\n",
            "None\n",
            "----------[test infomation]----------\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 66292 entries, 0 to 66291\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   PhraseId    66292 non-null  int64 \n",
            " 1   SentenceId  66292 non-null  int64 \n",
            " 2   Phrase      66292 non-null  object\n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 1.5+ MB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5MWDBTfKR05",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "83a0f202-459b-4036-edce-88c2abe71c55"
      },
      "source": [
        "train_tokens = Sentences2LemmaWords(train.Phrase)\n",
        "test_tokens = Sentences2LemmaWords(test.Phrase)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-14 08:30:56,306[DEBUG|preprocessing, 17] Sentence2LemmaWords: start\n",
            "/content/Sentiment Analysis/preprocessing/text_preprocessing.py:23: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
            "\n",
            "The code that caused this warning is on line 23 of the file /content/Sentiment Analysis/preprocessing/text_preprocessing.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
            "\n",
            "  sentence = BeautifulSoup(sentence).get_text()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1 / 156060 Phrase\r2 / 156060 Phrase\r3 / 156060 Phrase\r4 / 156060 Phrase\r5 / 156060 Phrase\r6 / 156060 Phrase\r7 / 156060 Phrase\r8 / 156060 Phrase\r9 / 156060 Phrase\r10 / 156060 Phrase\r11 / 156060 Phrase\r12 / 156060 Phrase\r13 / 156060 Phrase\r14 / 156060 Phrase\r15 / 156060 Phrase\r16 / 156060 Phrase\r17 / 156060 Phrase\r18 / 156060 Phrase\r19 / 156060 Phrase\r20 / 156060 Phrase\r21 / 156060 Phrase\r22 / 156060 Phrase\r23 / 156060 Phrase\r24 / 156060 Phrase\r25 / 156060 Phrase\r26 / 156060 Phrase\r27 / 156060 Phrase\r28 / 156060 Phrase\r29 / 156060 Phrase\r30 / 156060 Phrase\r31 / 156060 Phrase\r32 / 156060 Phrase\r33 / 156060 Phrase\r34 / 156060 Phrase\r35 / 156060 Phrase\r36 / 156060 Phrase\r37 / 156060 Phrase\r38 / 156060 Phrase\r39 / 156060 Phrase\r40 / 156060 Phrase\r41 / 156060 Phrase\r42 / 156060 Phrase\r43 / 156060 Phrase\r44 / 156060 Phrase\r45 / 156060 Phrase\r46 / 156060 Phrase\r47 / 156060 Phrase\r48 / 156060 Phrase\r49 / 156060 Phrase\r50 / 156060 Phrase\r51 / 156060 Phrase\r52 / 156060 Phrase\r53 / 156060 Phrase\r54 / 156060 Phrase\r55 / 156060 Phrase\r56 / 156060 Phrase\r57 / 156060 Phrase\r58 / 156060 Phrase\r59 / 156060 Phrase\r60 / 156060 Phrase\r61 / 156060 Phrase\r62 / 156060 Phrase\r63 / 156060 Phrase\r64 / 156060 Phrase\r65 / 156060 Phrase\r66 / 156060 Phrase\r67 / 156060 Phrase\r68 / 156060 Phrase\r69 / 156060 Phrase\r70 / 156060 Phrase\r71 / 156060 Phrase\r72 / 156060 Phrase\r73 / 156060 Phrase\r74 / 156060 Phrase\r75 / 156060 Phrase\r76 / 156060 Phrase\r77 / 156060 Phrase\r78 / 156060 Phrase\r79 / 156060 Phrase\r80 / 156060 Phrase\r81 / 156060 Phrase\r82 / 156060 Phrase\r83 / 156060 Phrase\r84 / 156060 Phrase\r85 / 156060 Phrase\r86 / 156060 Phrase\r87 / 156060 Phrase\r88 / 156060 Phrase\r89 / 156060 Phrase\r90 / 156060 Phrase\r91 / 156060 Phrase\r92 / 156060 Phrase\r93 / 156060 Phrase\r94 / 156060 Phrase\r95 / 156060 Phrase\r96 / 156060 Phrase\r97 / 156060 Phrase\r98 / 156060 Phrase\r99 / 156060 Phrase\r100 / 156060 Phrase\r101 / 156060 Phrase\r102 / 156060 Phrase\r103 / 156060 Phrase\r104 / 156060 Phrase\r105 / 156060 Phrase\r106 / 156060 Phrase\r107 / 156060 Phrase\r108 / 156060 Phrase\r109 / 156060 Phrase\r110 / 156060 Phrase\r111 / 156060 Phrase\r112 / 156060 Phrase\r113 / 156060 Phrase\r114 / 156060 Phrase\r115 / 156060 Phrase\r116 / 156060 Phrase\r117 / 156060 Phrase\r118 / 156060 Phrase\r119 / 156060 Phrase\r120 / 156060 Phrase\r121 / 156060 Phrase\r122 / 156060 Phrase\r123 / 156060 Phrase\r124 / 156060 Phrase\r125 / 156060 Phrase\r126 / 156060 Phrase\r127 / 156060 Phrase\r128 / 156060 Phrase\r129 / 156060 Phrase\r130 / 156060 Phrase\r131 / 156060 Phrase\r132 / 156060 Phrase\r133 / 156060 Phrase\r134 / 156060 Phrase\r135 / 156060 Phrase\r136 / 156060 Phrase\r137 / 156060 Phrase\r138 / 156060 Phrase\r139 / 156060 Phrase\r140 / 156060 Phrase\r141 / 156060 Phrase\r142 / 156060 Phrase\r143 / 156060 Phrase\r144 / 156060 Phrase\r145 / 156060 Phrase\r146 / 156060 Phrase\r147 / 156060 Phrase\r148 / 156060 Phrase\r149 / 156060 Phrase\r150 / 156060 Phrase\r151 / 156060 Phrase\r152 / 156060 Phrase\r153 / 156060 Phrase\r154 / 156060 Phrase\r155 / 156060 Phrase\r156 / 156060 Phrase\r157 / 156060 Phrase\r158 / 156060 Phrase\r159 / 156060 Phrase\r160 / 156060 Phrase\r161 / 156060 Phrase\r162 / 156060 Phrase\r163 / 156060 Phrase\r164 / 156060 Phrase\r165 / 156060 Phrase\r166 / 156060 Phrase\r167 / 156060 Phrase\r168 / 156060 Phrase\r169 / 156060 Phrase\r170 / 156060 Phrase\r171 / 156060 Phrase\r172 / 156060 Phrase\r173 / 156060 Phrase\r174 / 156060 Phrase\r175 / 156060 Phrase\r176 / 156060 Phrase\r177 / 156060 Phrase\r178 / 156060 Phrase\r179 / 156060 Phrase\r180 / 156060 Phrase\r181 / 156060 Phrase\r182 / 156060 Phrase\r183 / 156060 Phrase\r184 / 156060 Phrase\r185 / 156060 Phrase\r186 / 156060 Phrase\r187 / 156060 Phrase\r188 / 156060 Phrase\r189 / 156060 Phrase\r190 / 156060 Phrase\r191 / 156060 Phrase\r192 / 156060 Phrase\r193 / 156060 Phrase\r194 / 156060 Phrase\r195 / 156060 Phrase\r196 / 156060 Phrase\r197 / 156060 Phrase\r198 / 156060 Phrase\r199 / 156060 Phrase\r200 / 156060 Phrase\r201 / 156060 Phrase\r202 / 156060 Phrase\r203 / 156060 Phrase\r204 / 156060 Phrase\r205 / 156060 Phrase\r206 / 156060 Phrase\r207 / 156060 Phrase\r208 / 156060 Phrase\r209 / 156060 Phrase\r210 / 156060 Phrase\r211 / 156060 Phrase\r212 / 156060 Phrase\r213 / 156060 Phrase\r214 / 156060 Phrase\r215 / 156060 Phrase\r216 / 156060 Phrase\r217 / 156060 Phrase\r218 / 156060 Phrase\r219 / 156060 Phrase\r220 / 156060 Phrase\r221 / 156060 Phrase\r222 / 156060 Phrase\r223 / 156060 Phrase\r224 / 156060 Phrase\r225 / 156060 Phrase\r226 / 156060 Phrase\r227 / 156060 Phrase\r228 / 156060 Phrase\r229 / 156060 Phrase\r230 / 156060 Phrase\r231 / 156060 Phrase\r232 / 156060 Phrase\r233 / 156060 Phrase\r234 / 156060 Phrase\r235 / 156060 Phrase\r236 / 156060 Phrase\r237 / 156060 Phrase\r238 / 156060 Phrase\r239 / 156060 Phrase\r240 / 156060 Phrase\r241 / 156060 Phrase\r242 / 156060 Phrase\r243 / 156060 Phrase\r244 / 156060 Phrase\r245 / 156060 Phrase\r246 / 156060 Phrase\r247 / 156060 Phrase\r248 / 156060 Phrase\r249 / 156060 Phrase\r250 / 156060 Phrase\r251 / 156060 Phrase\r252 / 156060 Phrase\r253 / 156060 Phrase\r254 / 156060 Phrase\r255 / 156060 Phrase\r256 / 156060 Phrase\r257 / 156060 Phrase\r258 / 156060 Phrase\r259 / 156060 Phrase\r260 / 156060 Phrase\r261 / 156060 Phrase\r262 / 156060 Phrase\r263 / 156060 Phrase\r264 / 156060 Phrase\r265 / 156060 Phrase\r266 / 156060 Phrase\r267 / 156060 Phrase\r268 / 156060 Phrase\r269 / 156060 Phrase\r270 / 156060 Phrase\r271 / 156060 Phrase\r272 / 156060 Phrase\r273 / 156060 Phrase\r274 / 156060 Phrase\r275 / 156060 Phrase\r276 / 156060 Phrase\r277 / 156060 Phrase\r278 / 156060 Phrase\r279 / 156060 Phrase\r280 / 156060 Phrase"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:273: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
            "  ' Beautiful Soup.' % markup)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10901 / 156060 Phrase"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:273: UserWarning: \"b'log'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
            "  ' Beautiful Soup.' % markup)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "141630 / 156060 Phrase"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:273: UserWarning: \"b'model'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
            "  ' Beautiful Soup.' % markup)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "155982 / 156060 Phrase"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-14 08:33:03,566[DEBUG|preprocessing, 36] Sentence2LemmaWords: finish. 계산 시간 127.26092290878296sec\n",
            "2020-07-14 08:33:03,567[DEBUG|preprocessing, 17] Sentence2LemmaWords: start\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "156060 / 156060 Phrase\n",
            "66064 / 66292 Phrase"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-14 08:33:57,687[DEBUG|preprocessing, 36] Sentence2LemmaWords: finish. 계산 시간 54.11944055557251sec\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r66065 / 66292 Phrase\r66066 / 66292 Phrase\r66067 / 66292 Phrase\r66068 / 66292 Phrase\r66069 / 66292 Phrase\r66070 / 66292 Phrase\r66071 / 66292 Phrase\r66072 / 66292 Phrase\r66073 / 66292 Phrase\r66074 / 66292 Phrase\r66075 / 66292 Phrase\r66076 / 66292 Phrase\r66077 / 66292 Phrase\r66078 / 66292 Phrase\r66079 / 66292 Phrase\r66080 / 66292 Phrase\r66081 / 66292 Phrase\r66082 / 66292 Phrase\r66083 / 66292 Phrase\r66084 / 66292 Phrase\r66085 / 66292 Phrase\r66086 / 66292 Phrase\r66087 / 66292 Phrase\r66088 / 66292 Phrase\r66089 / 66292 Phrase\r66090 / 66292 Phrase\r66091 / 66292 Phrase\r66092 / 66292 Phrase\r66093 / 66292 Phrase\r66094 / 66292 Phrase\r66095 / 66292 Phrase\r66096 / 66292 Phrase\r66097 / 66292 Phrase\r66098 / 66292 Phrase\r66099 / 66292 Phrase\r66100 / 66292 Phrase\r66101 / 66292 Phrase\r66102 / 66292 Phrase\r66103 / 66292 Phrase\r66104 / 66292 Phrase\r66105 / 66292 Phrase\r66106 / 66292 Phrase\r66107 / 66292 Phrase\r66108 / 66292 Phrase\r66109 / 66292 Phrase\r66110 / 66292 Phrase\r66111 / 66292 Phrase\r66112 / 66292 Phrase\r66113 / 66292 Phrase\r66114 / 66292 Phrase\r66115 / 66292 Phrase\r66116 / 66292 Phrase\r66117 / 66292 Phrase\r66118 / 66292 Phrase\r66119 / 66292 Phrase\r66120 / 66292 Phrase\r66121 / 66292 Phrase\r66122 / 66292 Phrase\r66123 / 66292 Phrase\r66124 / 66292 Phrase\r66125 / 66292 Phrase\r66126 / 66292 Phrase\r66127 / 66292 Phrase\r66128 / 66292 Phrase\r66129 / 66292 Phrase\r66130 / 66292 Phrase\r66131 / 66292 Phrase\r66132 / 66292 Phrase\r66133 / 66292 Phrase\r66134 / 66292 Phrase\r66135 / 66292 Phrase\r66136 / 66292 Phrase\r66137 / 66292 Phrase\r66138 / 66292 Phrase\r66139 / 66292 Phrase\r66140 / 66292 Phrase\r66141 / 66292 Phrase\r66142 / 66292 Phrase\r66143 / 66292 Phrase\r66144 / 66292 Phrase\r66145 / 66292 Phrase\r66146 / 66292 Phrase\r66147 / 66292 Phrase\r66148 / 66292 Phrase\r66149 / 66292 Phrase\r66150 / 66292 Phrase\r66151 / 66292 Phrase\r66152 / 66292 Phrase\r66153 / 66292 Phrase\r66154 / 66292 Phrase\r66155 / 66292 Phrase\r66156 / 66292 Phrase\r66157 / 66292 Phrase\r66158 / 66292 Phrase\r66159 / 66292 Phrase\r66160 / 66292 Phrase\r66161 / 66292 Phrase\r66162 / 66292 Phrase\r66163 / 66292 Phrase\r66164 / 66292 Phrase\r66165 / 66292 Phrase\r66166 / 66292 Phrase\r66167 / 66292 Phrase\r66168 / 66292 Phrase\r66169 / 66292 Phrase\r66170 / 66292 Phrase\r66171 / 66292 Phrase\r66172 / 66292 Phrase\r66173 / 66292 Phrase\r66174 / 66292 Phrase\r66175 / 66292 Phrase\r66176 / 66292 Phrase\r66177 / 66292 Phrase\r66178 / 66292 Phrase\r66179 / 66292 Phrase\r66180 / 66292 Phrase\r66181 / 66292 Phrase\r66182 / 66292 Phrase\r66183 / 66292 Phrase\r66184 / 66292 Phrase\r66185 / 66292 Phrase\r66186 / 66292 Phrase\r66187 / 66292 Phrase\r66188 / 66292 Phrase\r66189 / 66292 Phrase\r66190 / 66292 Phrase\r66191 / 66292 Phrase\r66192 / 66292 Phrase\r66193 / 66292 Phrase\r66194 / 66292 Phrase\r66195 / 66292 Phrase\r66196 / 66292 Phrase\r66197 / 66292 Phrase\r66198 / 66292 Phrase\r66199 / 66292 Phrase\r66200 / 66292 Phrase\r66201 / 66292 Phrase\r66202 / 66292 Phrase\r66203 / 66292 Phrase\r66204 / 66292 Phrase\r66205 / 66292 Phrase\r66206 / 66292 Phrase\r66207 / 66292 Phrase\r66208 / 66292 Phrase\r66209 / 66292 Phrase\r66210 / 66292 Phrase\r66211 / 66292 Phrase\r66212 / 66292 Phrase\r66213 / 66292 Phrase\r66214 / 66292 Phrase\r66215 / 66292 Phrase\r66216 / 66292 Phrase\r66217 / 66292 Phrase\r66218 / 66292 Phrase\r66219 / 66292 Phrase\r66220 / 66292 Phrase\r66221 / 66292 Phrase\r66222 / 66292 Phrase\r66223 / 66292 Phrase\r66224 / 66292 Phrase\r66225 / 66292 Phrase\r66226 / 66292 Phrase\r66227 / 66292 Phrase\r66228 / 66292 Phrase\r66229 / 66292 Phrase\r66230 / 66292 Phrase\r66231 / 66292 Phrase\r66232 / 66292 Phrase\r66233 / 66292 Phrase\r66234 / 66292 Phrase\r66235 / 66292 Phrase\r66236 / 66292 Phrase\r66237 / 66292 Phrase\r66238 / 66292 Phrase\r66239 / 66292 Phrase\r66240 / 66292 Phrase\r66241 / 66292 Phrase\r66242 / 66292 Phrase\r66243 / 66292 Phrase\r66244 / 66292 Phrase\r66245 / 66292 Phrase\r66246 / 66292 Phrase\r66247 / 66292 Phrase\r66248 / 66292 Phrase\r66249 / 66292 Phrase\r66250 / 66292 Phrase\r66251 / 66292 Phrase\r66252 / 66292 Phrase\r66253 / 66292 Phrase\r66254 / 66292 Phrase\r66255 / 66292 Phrase\r66256 / 66292 Phrase\r66257 / 66292 Phrase\r66258 / 66292 Phrase\r66259 / 66292 Phrase\r66260 / 66292 Phrase\r66261 / 66292 Phrase\r66262 / 66292 Phrase\r66263 / 66292 Phrase\r66264 / 66292 Phrase\r66265 / 66292 Phrase\r66266 / 66292 Phrase\r66267 / 66292 Phrase\r66268 / 66292 Phrase\r66269 / 66292 Phrase\r66270 / 66292 Phrase\r66271 / 66292 Phrase\r66272 / 66292 Phrase\r66273 / 66292 Phrase\r66274 / 66292 Phrase\r66275 / 66292 Phrase\r66276 / 66292 Phrase\r66277 / 66292 Phrase\r66278 / 66292 Phrase\r66279 / 66292 Phrase\r66280 / 66292 Phrase\r66281 / 66292 Phrase\r66282 / 66292 Phrase\r66283 / 66292 Phrase\r66284 / 66292 Phrase\r66285 / 66292 Phrase\r66286 / 66292 Phrase\r66287 / 66292 Phrase\r66288 / 66292 Phrase\r66289 / 66292 Phrase\r66290 / 66292 Phrase\r66291 / 66292 Phrase\r66292 / 66292 Phrase\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTL953wgKR07",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "f25547b4-456f-4200-9784-78acf62e8920"
      },
      "source": [
        "unique_words, maxlen = GetUnique(train_tokens)\n",
        "print(len(unique_words), maxlen)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-14 08:33:57,701[DEBUG|preprocessing, 44] GetUnique: start\n",
            "2020-07-14 08:33:57,834[DEBUG|preprocessing, 56] GetUnique: finish. 계산 시간 0.13320517539978027sec\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "13745 48\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AWgFxM_KR0-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target = train.Sentiment\n",
        "y_target = to_categorical(target)\n",
        "num_classes = y_target.shape[1]"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5KNVN7pKR1B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_valid, y_train, y_valid = train_test_split(\n",
        "    train_tokens,\n",
        "    y_target,\n",
        "    test_size=0.2,\n",
        "    stratify=y_target)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSc3IsEdKR1D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "5e308beb-13a5-4a31-94d6-0411d53064de"
      },
      "source": [
        "tokenizer = setTokenizer(x_train, len(unique_words))\n",
        "x_train = LemmaWords2Seqeunces(x_train, tokenizer, maxlen)\n",
        "x_valid = LemmaWords2Seqeunces(x_valid, tokenizer, maxlen)\n",
        "x_test = LemmaWords2Seqeunces(test_tokens, tokenizer, maxlen)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-14 08:33:59,099[DEBUG|preprocessing, 63] setTokenizer: start\n",
            "2020-07-14 08:34:00,172[DEBUG|preprocessing, 70] setTokenizer: finish. 계산 시간 1.0727298259735107sec\n",
            "2020-07-14 08:34:00,174[DEBUG|preprocessing, 77] LemmaWords2Seqeunces: start\n",
            "2020-07-14 08:34:01,823[DEBUG|preprocessing, 84] LemmaWords2Seqeunces: finish. 계산 시간 1.6493120193481445sec\n",
            "2020-07-14 08:34:01,828[DEBUG|preprocessing, 77] LemmaWords2Seqeunces: start\n",
            "2020-07-14 08:34:02,177[DEBUG|preprocessing, 84] LemmaWords2Seqeunces: finish. 계산 시간 0.3494713306427002sec\n",
            "2020-07-14 08:34:02,180[DEBUG|preprocessing, 77] LemmaWords2Seqeunces: start\n",
            "2020-07-14 08:34:02,789[DEBUG|preprocessing, 84] LemmaWords2Seqeunces: finish. 계산 시간 0.6090283393859863sec\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxyVUnf9KR1G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "f5535119-a70a-45e6-bb5b-030060d2fcb2"
      },
      "source": [
        "model = LSTM_model(len(unique_words), maxlen, num_classes)\n",
        "\n",
        "logger = Logger('main')\n",
        "start_time = time.time()\n",
        "logger.debug('fit start')\n",
        "\n",
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          validation_data=(x_valid, y_valid),\n",
        "          epochs=5,\n",
        "          batch_size=1024,\n",
        "          verbose=1)\n",
        "\n",
        "fit_time = time.time() - start_time\n",
        "logger.debug('fit end. fit_time {}'.format(fit_time))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-14 08:34:02,806[DEBUG|LSTM_model_generate, 9] LSTM_model: start\n",
            "2020-07-14 08:34:10,343[DEBUG|LSTM_model_generate, 20] LSTM_model: finish\n",
            "2020-07-14 08:34:10,345[DEBUG|main, 5] fit start\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 124848 samples, validate on 31212 samples\n",
            "Epoch 1/5\n",
            "124848/124848 [==============================] - 24s 196us/step - loss: 1.1018 - accuracy: 0.5628 - val_loss: 0.9091 - val_accuracy: 0.6281\n",
            "Epoch 2/5\n",
            "124848/124848 [==============================] - 22s 177us/step - loss: 0.8132 - accuracy: 0.6686 - val_loss: 0.8395 - val_accuracy: 0.6558\n",
            "Epoch 3/5\n",
            "124848/124848 [==============================] - 22s 177us/step - loss: 0.7337 - accuracy: 0.6985 - val_loss: 0.8307 - val_accuracy: 0.6621\n",
            "Epoch 4/5\n",
            "124848/124848 [==============================] - 22s 180us/step - loss: 0.6881 - accuracy: 0.7152 - val_loss: 0.8338 - val_accuracy: 0.6640\n",
            "Epoch 5/5\n",
            "124848/124848 [==============================] - 22s 179us/step - loss: 0.6543 - accuracy: 0.7258 - val_loss: 0.8435 - val_accuracy: 0.6618\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-14 08:36:04,805[DEBUG|main, 15] fit end. fit_time 114.45991396903992\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QJDWrleKR1I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict_classes(x_test)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'PhraseId': test.PhraseId,\n",
        "    'Sentiment': y_pred\n",
        "})\n",
        "submission.to_csv(folder_path + 'submission.csv', index=False)"
      ],
      "execution_count": 47,
      "outputs": []
    }
  ]
}