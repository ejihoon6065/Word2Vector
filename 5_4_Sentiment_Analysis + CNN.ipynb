{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "5.4.Sentiment Analysis.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ejihoon6065/-/blob/master/5_4_Sentiment_Analysis%20%2B%20CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fk54oXIXKyUu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3b8acf1-1bea-4821-d122-1cfa2ea38b56"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUKrmZqaK5Jb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "5b23e295-0e33-4d0e-a4fe-eb756bd9b89c"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'5.4.Sentiment Analysis.ipynb'\t log\t   preprocessing  'Untitled Folder'\n",
            "'5.4.Sentiment Analysis.zip'\t log.zip   test.tsv\n",
            " data\t\t\t\t model\t   train.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkYizESTK74_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f2ee242f-ba83-4722-8d44-502d980da6f4"
      },
      "source": [
        "cd 5.4.Sentiment Analysis"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '5.4.Sentiment Analysis'\n",
            "/content/Sentiment Analysis\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7EEFXKPW8i5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c8cfceca-edc7-4bad-862f-46833a605781"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'/content/Sentiment Analysis'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sr7DljeNKR0z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from model.LSTM import LSTM_model\n",
        "from preprocessing.text_preprocessing import Sentences2LemmaWords\n",
        "from preprocessing.text_preprocessing import GetUnique\n",
        "from preprocessing.text_preprocessing import setTokenizer\n",
        "from preprocessing.text_preprocessing import LemmaWords2Seqeunces\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "import time\n",
        "from log.logger import Logger"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWn9XdbpKR03",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "outputId": "6fd5965b-4185-4ecd-e9e9-527cb73fd2ee"
      },
      "source": [
        "folder_path = './data/'\n",
        "train = pd.read_csv('train.tsv', sep='\\t')\n",
        "test = pd.read_csv('test.tsv', sep='\\t')\n",
        "\n",
        "print('train data shape: ', train.shape)\n",
        "print('test data shape: ', test.shape)\n",
        "print('----------[train infomation]----------')\n",
        "print(train.info())\n",
        "print('----------[test infomation]----------')\n",
        "print(test.info())"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train data shape:  (156060, 4)\n",
            "test data shape:  (66292, 3)\n",
            "----------[train infomation]----------\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 156060 entries, 0 to 156059\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count   Dtype \n",
            "---  ------      --------------   ----- \n",
            " 0   PhraseId    156060 non-null  int64 \n",
            " 1   SentenceId  156060 non-null  int64 \n",
            " 2   Phrase      156060 non-null  object\n",
            " 3   Sentiment   156060 non-null  int64 \n",
            "dtypes: int64(3), object(1)\n",
            "memory usage: 4.8+ MB\n",
            "None\n",
            "----------[test infomation]----------\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 66292 entries, 0 to 66291\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   PhraseId    66292 non-null  int64 \n",
            " 1   SentenceId  66292 non-null  int64 \n",
            " 2   Phrase      66292 non-null  object\n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 1.5+ MB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5MWDBTfKR05",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "74deecc3-5afb-49ef-a83b-14445aa78bf4"
      },
      "source": [
        "train_tokens = Sentences2LemmaWords(train.Phrase)\n",
        "test_tokens = Sentences2LemmaWords(test.Phrase)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-14 08:50:00,135[DEBUG|preprocessing, 17] Sentence2LemmaWords: start\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1 / 156060 Phrase\r2 / 156060 Phrase\r3 / 156060 Phrase\r4 / 156060 Phrase\r5 / 156060 Phrase\r6 / 156060 Phrase\r7 / 156060 Phrase\r8 / 156060 Phrase\r9 / 156060 Phrase\r10 / 156060 Phrase\r11 / 156060 Phrase\r12 / 156060 Phrase\r13 / 156060 Phrase\r14 / 156060 Phrase\r15 / 156060 Phrase\r16 / 156060 Phrase\r17 / 156060 Phrase\r18 / 156060 Phrase\r19 / 156060 Phrase\r20 / 156060 Phrase\r21 / 156060 Phrase\r22 / 156060 Phrase\r23 / 156060 Phrase\r24 / 156060 Phrase\r25 / 156060 Phrase\r26 / 156060 Phrase\r27 / 156060 Phrase\r28 / 156060 Phrase\r29 / 156060 Phrase\r30 / 156060 Phrase\r31 / 156060 Phrase\r32 / 156060 Phrase\r33 / 156060 Phrase\r34 / 156060 Phrase\r35 / 156060 Phrase\r36 / 156060 Phrase\r37 / 156060 Phrase\r38 / 156060 Phrase\r39 / 156060 Phrase\r40 / 156060 Phrase\r41 / 156060 Phrase\r42 / 156060 Phrase\r43 / 156060 Phrase\r44 / 156060 Phrase\r45 / 156060 Phrase\r46 / 156060 Phrase\r47 / 156060 Phrase\r48 / 156060 Phrase\r49 / 156060 Phrase\r50 / 156060 Phrase\r51 / 156060 Phrase\r52 / 156060 Phrase\r53 / 156060 Phrase\r54 / 156060 Phrase\r55 / 156060 Phrase\r56 / 156060 Phrase\r57 / 156060 Phrase\r58 / 156060 Phrase\r59 / 156060 Phrase\r60 / 156060 Phrase\r61 / 156060 Phrase\r62 / 156060 Phrase\r63 / 156060 Phrase\r64 / 156060 Phrase\r65 / 156060 Phrase\r66 / 156060 Phrase\r67 / 156060 Phrase\r68 / 156060 Phrase\r69 / 156060 Phrase\r70 / 156060 Phrase\r71 / 156060 Phrase\r72 / 156060 Phrase\r73 / 156060 Phrase\r74 / 156060 Phrase\r75 / 156060 Phrase\r76 / 156060 Phrase\r77 / 156060 Phrase\r78 / 156060 Phrase\r79 / 156060 Phrase\r80 / 156060 Phrase\r81 / 156060 Phrase\r82 / 156060 Phrase\r83 / 156060 Phrase\r84 / 156060 Phrase\r85 / 156060 Phrase\r86 / 156060 Phrase\r87 / 156060 Phrase\r88 / 156060 Phrase\r89 / 156060 Phrase\r90 / 156060 Phrase\r91 / 156060 Phrase\r92 / 156060 Phrase\r93 / 156060 Phrase\r94 / 156060 Phrase\r95 / 156060 Phrase\r96 / 156060 Phrase\r97 / 156060 Phrase\r98 / 156060 Phrase\r99 / 156060 Phrase\r100 / 156060 Phrase\r101 / 156060 Phrase\r102 / 156060 Phrase\r103 / 156060 Phrase\r104 / 156060 Phrase\r105 / 156060 Phrase\r106 / 156060 Phrase\r107 / 156060 Phrase\r108 / 156060 Phrase\r109 / 156060 Phrase\r110 / 156060 Phrase\r111 / 156060 Phrase\r112 / 156060 Phrase\r113 / 156060 Phrase\r114 / 156060 Phrase\r115 / 156060 Phrase\r116 / 156060 Phrase\r117 / 156060 Phrase\r118 / 156060 Phrase\r119 / 156060 Phrase\r120 / 156060 Phrase\r121 / 156060 Phrase\r122 / 156060 Phrase\r123 / 156060 Phrase\r124 / 156060 Phrase\r125 / 156060 Phrase\r126 / 156060 Phrase\r127 / 156060 Phrase\r128 / 156060 Phrase\r129 / 156060 Phrase\r130 / 156060 Phrase\r131 / 156060 Phrase\r132 / 156060 Phrase\r133 / 156060 Phrase\r134 / 156060 Phrase\r135 / 156060 Phrase\r136 / 156060 Phrase\r137 / 156060 Phrase\r138 / 156060 Phrase\r139 / 156060 Phrase\r140 / 156060 Phrase\r141 / 156060 Phrase\r142 / 156060 Phrase\r143 / 156060 Phrase\r144 / 156060 Phrase\r145 / 156060 Phrase\r146 / 156060 Phrase\r147 / 156060 Phrase\r148 / 156060 Phrase\r149 / 156060 Phrase\r150 / 156060 Phrase\r151 / 156060 Phrase\r152 / 156060 Phrase\r153 / 156060 Phrase\r154 / 156060 Phrase\r155 / 156060 Phrase\r156 / 156060 Phrase\r157 / 156060 Phrase\r158 / 156060 Phrase\r159 / 156060 Phrase\r160 / 156060 Phrase\r161 / 156060 Phrase\r162 / 156060 Phrase\r163 / 156060 Phrase\r164 / 156060 Phrase\r165 / 156060 Phrase\r166 / 156060 Phrase\r167 / 156060 Phrase\r168 / 156060 Phrase\r169 / 156060 Phrase\r170 / 156060 Phrase\r171 / 156060 Phrase\r172 / 156060 Phrase\r173 / 156060 Phrase\r174 / 156060 Phrase\r175 / 156060 Phrase\r176 / 156060 Phrase\r177 / 156060 Phrase\r178 / 156060 Phrase\r179 / 156060 Phrase\r180 / 156060 Phrase\r181 / 156060 Phrase\r182 / 156060 Phrase\r183 / 156060 Phrase\r184 / 156060 Phrase\r185 / 156060 Phrase\r186 / 156060 Phrase\r187 / 156060 Phrase\r188 / 156060 Phrase\r189 / 156060 Phrase\r190 / 156060 Phrase\r191 / 156060 Phrase\r192 / 156060 Phrase\r193 / 156060 Phrase\r194 / 156060 Phrase\r195 / 156060 Phrase\r196 / 156060 Phrase\r197 / 156060 Phrase\r198 / 156060 Phrase\r199 / 156060 Phrase\r200 / 156060 Phrase\r201 / 156060 Phrase\r202 / 156060 Phrase\r203 / 156060 Phrase\r204 / 156060 Phrase\r205 / 156060 Phrase\r206 / 156060 Phrase\r207 / 156060 Phrase\r208 / 156060 Phrase\r209 / 156060 Phrase\r210 / 156060 Phrase\r211 / 156060 Phrase\r212 / 156060 Phrase"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/Sentiment Analysis/preprocessing/text_preprocessing.py:23: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
            "\n",
            "The code that caused this warning is on line 23 of the file /content/Sentiment Analysis/preprocessing/text_preprocessing.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
            "\n",
            "  sentence = BeautifulSoup(sentence).get_text()\n",
            "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:273: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
            "  ' Beautiful Soup.' % markup)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10810 / 156060 Phrase"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:273: UserWarning: \"b'log'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
            "  ' Beautiful Soup.' % markup)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "141596 / 156060 Phrase"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:273: UserWarning: \"b'model'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
            "  ' Beautiful Soup.' % markup)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "155956 / 156060 Phrase"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-14 08:52:04,229[DEBUG|preprocessing, 36] Sentence2LemmaWords: finish. 계산 시간 124.09361577033997sec\n",
            "2020-07-14 08:52:04,292[DEBUG|preprocessing, 17] Sentence2LemmaWords: start\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "156060 / 156060 Phrase\n",
            "66030 / 66292 Phrase"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-14 08:52:57,000[DEBUG|preprocessing, 36] Sentence2LemmaWords: finish. 계산 시간 52.7087025642395sec\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r66031 / 66292 Phrase\r66032 / 66292 Phrase\r66033 / 66292 Phrase\r66034 / 66292 Phrase\r66035 / 66292 Phrase\r66036 / 66292 Phrase\r66037 / 66292 Phrase\r66038 / 66292 Phrase\r66039 / 66292 Phrase\r66040 / 66292 Phrase\r66041 / 66292 Phrase\r66042 / 66292 Phrase\r66043 / 66292 Phrase\r66044 / 66292 Phrase\r66045 / 66292 Phrase\r66046 / 66292 Phrase\r66047 / 66292 Phrase\r66048 / 66292 Phrase\r66049 / 66292 Phrase\r66050 / 66292 Phrase\r66051 / 66292 Phrase\r66052 / 66292 Phrase\r66053 / 66292 Phrase\r66054 / 66292 Phrase\r66055 / 66292 Phrase\r66056 / 66292 Phrase\r66057 / 66292 Phrase\r66058 / 66292 Phrase\r66059 / 66292 Phrase\r66060 / 66292 Phrase\r66061 / 66292 Phrase\r66062 / 66292 Phrase\r66063 / 66292 Phrase\r66064 / 66292 Phrase\r66065 / 66292 Phrase\r66066 / 66292 Phrase\r66067 / 66292 Phrase\r66068 / 66292 Phrase\r66069 / 66292 Phrase\r66070 / 66292 Phrase\r66071 / 66292 Phrase\r66072 / 66292 Phrase\r66073 / 66292 Phrase\r66074 / 66292 Phrase\r66075 / 66292 Phrase\r66076 / 66292 Phrase\r66077 / 66292 Phrase\r66078 / 66292 Phrase\r66079 / 66292 Phrase\r66080 / 66292 Phrase\r66081 / 66292 Phrase\r66082 / 66292 Phrase\r66083 / 66292 Phrase\r66084 / 66292 Phrase\r66085 / 66292 Phrase\r66086 / 66292 Phrase\r66087 / 66292 Phrase\r66088 / 66292 Phrase\r66089 / 66292 Phrase\r66090 / 66292 Phrase\r66091 / 66292 Phrase\r66092 / 66292 Phrase\r66093 / 66292 Phrase\r66094 / 66292 Phrase\r66095 / 66292 Phrase\r66096 / 66292 Phrase\r66097 / 66292 Phrase\r66098 / 66292 Phrase\r66099 / 66292 Phrase\r66100 / 66292 Phrase\r66101 / 66292 Phrase\r66102 / 66292 Phrase\r66103 / 66292 Phrase\r66104 / 66292 Phrase\r66105 / 66292 Phrase\r66106 / 66292 Phrase\r66107 / 66292 Phrase\r66108 / 66292 Phrase\r66109 / 66292 Phrase\r66110 / 66292 Phrase\r66111 / 66292 Phrase\r66112 / 66292 Phrase\r66113 / 66292 Phrase\r66114 / 66292 Phrase\r66115 / 66292 Phrase\r66116 / 66292 Phrase\r66117 / 66292 Phrase\r66118 / 66292 Phrase\r66119 / 66292 Phrase\r66120 / 66292 Phrase\r66121 / 66292 Phrase\r66122 / 66292 Phrase\r66123 / 66292 Phrase\r66124 / 66292 Phrase\r66125 / 66292 Phrase\r66126 / 66292 Phrase\r66127 / 66292 Phrase\r66128 / 66292 Phrase\r66129 / 66292 Phrase\r66130 / 66292 Phrase\r66131 / 66292 Phrase\r66132 / 66292 Phrase\r66133 / 66292 Phrase\r66134 / 66292 Phrase\r66135 / 66292 Phrase\r66136 / 66292 Phrase\r66137 / 66292 Phrase\r66138 / 66292 Phrase\r66139 / 66292 Phrase\r66140 / 66292 Phrase\r66141 / 66292 Phrase\r66142 / 66292 Phrase\r66143 / 66292 Phrase\r66144 / 66292 Phrase\r66145 / 66292 Phrase\r66146 / 66292 Phrase\r66147 / 66292 Phrase\r66148 / 66292 Phrase\r66149 / 66292 Phrase\r66150 / 66292 Phrase\r66151 / 66292 Phrase\r66152 / 66292 Phrase\r66153 / 66292 Phrase\r66154 / 66292 Phrase\r66155 / 66292 Phrase\r66156 / 66292 Phrase\r66157 / 66292 Phrase\r66158 / 66292 Phrase\r66159 / 66292 Phrase\r66160 / 66292 Phrase\r66161 / 66292 Phrase\r66162 / 66292 Phrase\r66163 / 66292 Phrase\r66164 / 66292 Phrase\r66165 / 66292 Phrase\r66166 / 66292 Phrase\r66167 / 66292 Phrase\r66168 / 66292 Phrase\r66169 / 66292 Phrase\r66170 / 66292 Phrase\r66171 / 66292 Phrase\r66172 / 66292 Phrase\r66173 / 66292 Phrase\r66174 / 66292 Phrase\r66175 / 66292 Phrase\r66176 / 66292 Phrase\r66177 / 66292 Phrase\r66178 / 66292 Phrase\r66179 / 66292 Phrase\r66180 / 66292 Phrase\r66181 / 66292 Phrase\r66182 / 66292 Phrase\r66183 / 66292 Phrase\r66184 / 66292 Phrase\r66185 / 66292 Phrase\r66186 / 66292 Phrase\r66187 / 66292 Phrase\r66188 / 66292 Phrase\r66189 / 66292 Phrase\r66190 / 66292 Phrase\r66191 / 66292 Phrase\r66192 / 66292 Phrase\r66193 / 66292 Phrase\r66194 / 66292 Phrase\r66195 / 66292 Phrase\r66196 / 66292 Phrase\r66197 / 66292 Phrase\r66198 / 66292 Phrase\r66199 / 66292 Phrase\r66200 / 66292 Phrase\r66201 / 66292 Phrase\r66202 / 66292 Phrase\r66203 / 66292 Phrase\r66204 / 66292 Phrase\r66205 / 66292 Phrase\r66206 / 66292 Phrase\r66207 / 66292 Phrase\r66208 / 66292 Phrase\r66209 / 66292 Phrase\r66210 / 66292 Phrase\r66211 / 66292 Phrase\r66212 / 66292 Phrase\r66213 / 66292 Phrase\r66214 / 66292 Phrase\r66215 / 66292 Phrase\r66216 / 66292 Phrase\r66217 / 66292 Phrase\r66218 / 66292 Phrase\r66219 / 66292 Phrase\r66220 / 66292 Phrase\r66221 / 66292 Phrase\r66222 / 66292 Phrase\r66223 / 66292 Phrase\r66224 / 66292 Phrase\r66225 / 66292 Phrase\r66226 / 66292 Phrase\r66227 / 66292 Phrase\r66228 / 66292 Phrase\r66229 / 66292 Phrase\r66230 / 66292 Phrase\r66231 / 66292 Phrase\r66232 / 66292 Phrase\r66233 / 66292 Phrase\r66234 / 66292 Phrase\r66235 / 66292 Phrase\r66236 / 66292 Phrase\r66237 / 66292 Phrase\r66238 / 66292 Phrase\r66239 / 66292 Phrase\r66240 / 66292 Phrase\r66241 / 66292 Phrase\r66242 / 66292 Phrase\r66243 / 66292 Phrase\r66244 / 66292 Phrase\r66245 / 66292 Phrase\r66246 / 66292 Phrase\r66247 / 66292 Phrase\r66248 / 66292 Phrase\r66249 / 66292 Phrase\r66250 / 66292 Phrase\r66251 / 66292 Phrase\r66252 / 66292 Phrase\r66253 / 66292 Phrase\r66254 / 66292 Phrase\r66255 / 66292 Phrase\r66256 / 66292 Phrase\r66257 / 66292 Phrase\r66258 / 66292 Phrase\r66259 / 66292 Phrase\r66260 / 66292 Phrase\r66261 / 66292 Phrase\r66262 / 66292 Phrase\r66263 / 66292 Phrase\r66264 / 66292 Phrase\r66265 / 66292 Phrase\r66266 / 66292 Phrase\r66267 / 66292 Phrase\r66268 / 66292 Phrase\r66269 / 66292 Phrase\r66270 / 66292 Phrase\r66271 / 66292 Phrase\r66272 / 66292 Phrase\r66273 / 66292 Phrase\r66274 / 66292 Phrase\r66275 / 66292 Phrase\r66276 / 66292 Phrase\r66277 / 66292 Phrase\r66278 / 66292 Phrase\r66279 / 66292 Phrase\r66280 / 66292 Phrase\r66281 / 66292 Phrase\r66282 / 66292 Phrase\r66283 / 66292 Phrase\r66284 / 66292 Phrase\r66285 / 66292 Phrase\r66286 / 66292 Phrase\r66287 / 66292 Phrase\r66288 / 66292 Phrase\r66289 / 66292 Phrase\r66290 / 66292 Phrase\r66291 / 66292 Phrase\r66292 / 66292 Phrase\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTL953wgKR07",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "422ceb74-b1ca-4a17-8665-8eeb862ddf32"
      },
      "source": [
        "unique_words, maxlen = GetUnique(train_tokens)\n",
        "print(len(unique_words), maxlen)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-14 08:52:57,037[DEBUG|preprocessing, 44] GetUnique: start\n",
            "2020-07-14 08:52:57,189[DEBUG|preprocessing, 56] GetUnique: finish. 계산 시간 0.15117192268371582sec\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "13745 48\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AWgFxM_KR0-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target = train.Sentiment\n",
        "y_target = to_categorical(target)\n",
        "num_classes = y_target.shape[1]"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5KNVN7pKR1B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_valid, y_train, y_valid = train_test_split(\n",
        "    train_tokens,\n",
        "    y_target,\n",
        "    test_size=0.2,\n",
        "    stratify=y_target)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSc3IsEdKR1D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "70d6e127-c4ad-4b8a-c477-62f82397824b"
      },
      "source": [
        "tokenizer = setTokenizer(x_train, len(unique_words))\n",
        "x_train = LemmaWords2Seqeunces(x_train, tokenizer, maxlen)\n",
        "x_valid = LemmaWords2Seqeunces(x_valid, tokenizer, maxlen)\n",
        "x_test = LemmaWords2Seqeunces(test_tokens, tokenizer, maxlen)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-14 08:52:58,417[DEBUG|preprocessing, 63] setTokenizer: start\n",
            "2020-07-14 08:52:59,377[DEBUG|preprocessing, 70] setTokenizer: finish. 계산 시간 0.9602627754211426sec\n",
            "2020-07-14 08:52:59,380[DEBUG|preprocessing, 77] LemmaWords2Seqeunces: start\n",
            "2020-07-14 08:53:01,107[DEBUG|preprocessing, 84] LemmaWords2Seqeunces: finish. 계산 시간 1.7272887229919434sec\n",
            "2020-07-14 08:53:01,112[DEBUG|preprocessing, 77] LemmaWords2Seqeunces: start\n",
            "2020-07-14 08:53:01,462[DEBUG|preprocessing, 84] LemmaWords2Seqeunces: finish. 계산 시간 0.3498494625091553sec\n",
            "2020-07-14 08:53:01,467[DEBUG|preprocessing, 77] LemmaWords2Seqeunces: start\n",
            "2020-07-14 08:53:02,105[DEBUG|preprocessing, 84] LemmaWords2Seqeunces: finish. 계산 시간 0.6381514072418213sec\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxyVUnf9KR1G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "62080166-dbd4-45fc-8131-48391c7a0eb8"
      },
      "source": [
        "model = LSTM_model(len(unique_words), maxlen, num_classes)\n",
        "\n",
        "logger = Logger('main')\n",
        "start_time = time.time()\n",
        "logger.debug('fit start')\n",
        "\n",
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          validation_data=(x_valid, y_valid),\n",
        "          epochs=5,\n",
        "          batch_size=1024,\n",
        "          verbose=1)\n",
        "\n",
        "fit_time = time.time() - start_time\n",
        "logger.debug('fit end. fit_time {}'.format(fit_time))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-14 08:53:02,119[DEBUG|LSTM_model_generate, 9] LSTM_model: start\n",
            "2020-07-14 08:53:02,343[DEBUG|LSTM_model_generate, 20] LSTM_model: finish\n",
            "2020-07-14 08:53:02,345[DEBUG|main, 5] fit start\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 124848 samples, validate on 31212 samples\n",
            "Epoch 1/5\n",
            "124848/124848 [==============================] - 23s 184us/step - loss: 1.0929 - accuracy: 0.5679 - val_loss: 0.9013 - val_accuracy: 0.6344\n",
            "Epoch 2/5\n",
            "124848/124848 [==============================] - 22s 179us/step - loss: 0.8091 - accuracy: 0.6702 - val_loss: 0.8409 - val_accuracy: 0.6573\n",
            "Epoch 3/5\n",
            "124848/124848 [==============================] - 23s 182us/step - loss: 0.7337 - accuracy: 0.6970 - val_loss: 0.8313 - val_accuracy: 0.6631\n",
            "Epoch 4/5\n",
            "124848/124848 [==============================] - 23s 181us/step - loss: 0.6876 - accuracy: 0.7146 - val_loss: 0.8375 - val_accuracy: 0.6608\n",
            "Epoch 5/5\n",
            "124848/124848 [==============================] - 23s 183us/step - loss: 0.6524 - accuracy: 0.7260 - val_loss: 0.8424 - val_accuracy: 0.6647\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-14 08:54:56,834[DEBUG|main, 15] fit end. fit_time 114.48963284492493\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QJDWrleKR1I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict_classes(x_test)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'PhraseId': test.PhraseId,\n",
        "    'Sentiment': y_pred\n",
        "})\n",
        "submission.to_csv(folder_path + 'submission.csv', index=False)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuYkRM_NlLab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding,Dropout,Conv1D,GlobalMaxPool1D,Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjwoUPQolgVf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim=256\n",
        "batch_size=256"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfn2MTZRlqOd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "5d498f37-c96a-45c5-bbc0-9ad2440e99dc"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding(len(unique_words),300))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Conv1D(300,3,padding='valid',activation='relu'))\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(5,activation='softmax'))\n",
        "\n",
        "es=EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=3)\n",
        "mc=ModelCheckpoint('best_model.h5',monitor='val_acc',mode='max',verbose=1,save_best_only=True)\n",
        "\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc'])\n",
        "history=model.fit(x_train,y_train,epochs=20,validation_data=(x_valid,y_valid),callbacks=[es,mc])"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "3902/3902 [==============================] - ETA: 0s - loss: 0.9692 - acc: 0.6085\n",
            "Epoch 00001: val_acc improved from -inf to 0.64478, saving model to best_model.h5\n",
            "3902/3902 [==============================] - 213s 55ms/step - loss: 0.9692 - acc: 0.6085 - val_loss: 0.8499 - val_acc: 0.6448\n",
            "Epoch 2/20\n",
            "3901/3902 [============================>.] - ETA: 0s - loss: 0.7871 - acc: 0.6773\n",
            "Epoch 00002: val_acc improved from 0.64478 to 0.66324, saving model to best_model.h5\n",
            "3902/3902 [==============================] - 210s 54ms/step - loss: 0.7870 - acc: 0.6773 - val_loss: 0.8216 - val_acc: 0.6632\n",
            "Epoch 3/20\n",
            "3902/3902 [==============================] - ETA: 0s - loss: 0.7123 - acc: 0.7035\n",
            "Epoch 00003: val_acc improved from 0.66324 to 0.66763, saving model to best_model.h5\n",
            "3902/3902 [==============================] - 202s 52ms/step - loss: 0.7123 - acc: 0.7035 - val_loss: 0.8269 - val_acc: 0.6676\n",
            "Epoch 4/20\n",
            "3902/3902 [==============================] - ETA: 0s - loss: 0.6641 - acc: 0.7205\n",
            "Epoch 00004: val_acc did not improve from 0.66763\n",
            "3902/3902 [==============================] - 207s 53ms/step - loss: 0.6641 - acc: 0.7205 - val_loss: 0.8453 - val_acc: 0.6609\n",
            "Epoch 5/20\n",
            "3902/3902 [==============================] - ETA: 0s - loss: 0.6250 - acc: 0.7339\n",
            "Epoch 00005: val_acc did not improve from 0.66763\n",
            "3902/3902 [==============================] - 197s 50ms/step - loss: 0.6250 - acc: 0.7339 - val_loss: 0.8879 - val_acc: 0.6646\n",
            "Epoch 00005: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2grL96vlszK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}