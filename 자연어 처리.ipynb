{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv('all_stocks_5yr.csv')     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(995, 7) (249, 7)\n",
      "(995,) (249,)\n"
     ]
    }
   ],
   "source": [
    "cl = data[data['Name'] =='MMM'].close\n",
    "\n",
    "cv = cl.values\n",
    "scl = MinMaxScaler()\n",
    "cv = cv.reshape(cv.shape[0],1)\n",
    "cv = scl.fit_transform(cv)\n",
    "\n",
    "def processData(data,lb,gap) :\n",
    "    X,Y = [],[]\n",
    "    for i in range(len(data)-lb-gap-1):\n",
    "        X.append(data[i:(i+lb),0])\n",
    "        Y.append(data[(i+lb+gap),0])\n",
    "    return np.array(X),np.array(Y)\n",
    "\n",
    "X,y = processData(cv,7,7)\n",
    "\n",
    "X_train, X_test = X[:int(X.shape[0]*0.80)],X[int(X.shape[0]*0.80):]\n",
    "y_train, y_test = y[:int(y.shape[0]*0.80)],y[int(y.shape[0]*0.80):]\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 256)               264192    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 264,449\n",
      "Trainable params: 264,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.0026 - val_loss: 0.0276\n",
      "Epoch 2/300\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 0.0081 - val_loss: 0.0029\n",
      "Epoch 3/300\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 4/300\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 9.3020e-04 - val_loss: 0.0027\n",
      "Epoch 5/300\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 6/300\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 7/300\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0011 - val_loss: 0.0026\n",
      "Epoch 8/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0011 - val_loss: 0.0026\n",
      "Epoch 9/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 10/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0012 - val_loss: 0.0031\n",
      "Epoch 11/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0011 - val_loss: 0.0034\n",
      "Epoch 12/300\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0012 - val_loss: 0.0035\n",
      "Epoch 13/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 14/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 15/300\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 16/300\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0010 - val_loss: 0.0048\n",
      "Epoch 17/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0010 - val_loss: 0.0051\n",
      "Epoch 18/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0010 - val_loss: 0.0054\n",
      "Epoch 19/300\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0010 - val_loss: 0.0056\n",
      "Epoch 20/300\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0010 - val_loss: 0.0058\n",
      "Epoch 21/300\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0010 - val_loss: 0.0059\n",
      "Epoch 22/300\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 0.0010 - val_loss: 0.0061\n",
      "Epoch 23/300\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0010 - val_loss: 0.0062\n",
      "Epoch 24/300\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0010 - val_loss: 0.0063\n",
      "Epoch 25/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0010 - val_loss: 0.0063\n",
      "Epoch 26/300\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0010 - val_loss: 0.0064\n",
      "Epoch 27/300\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0010 - val_loss: 0.0064\n",
      "Epoch 28/300\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 9.9939e-04 - val_loss: 0.0064\n",
      "Epoch 29/300\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 9.9710e-04 - val_loss: 0.0064\n",
      "Epoch 30/300\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 9.9520e-04 - val_loss: 0.0064\n",
      "Epoch 31/300\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 9.9208e-04 - val_loss: 0.0064\n",
      "Epoch 32/300\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 9.8984e-04 - val_loss: 0.0064\n",
      "Epoch 33/300\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 9.8592e-04 - val_loss: 0.0064\n",
      "Epoch 34/300\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 9.8361e-04 - val_loss: 0.0064\n",
      "Epoch 35/300\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 9.7892e-04 - val_loss: 0.0063\n",
      "Epoch 36/300\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 9.7682e-04 - val_loss: 0.0063\n",
      "Epoch 37/300\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 9.7132e-04 - val_loss: 0.0063\n",
      "Epoch 38/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 9.6978e-04 - val_loss: 0.0063\n",
      "Epoch 39/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 9.6333e-04 - val_loss: 0.0062\n",
      "Epoch 40/300\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 9.6274e-04 - val_loss: 0.0062\n",
      "Epoch 41/300\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 9.5512e-04 - val_loss: 0.0062\n",
      "Epoch 42/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 9.5596e-04 - val_loss: 0.0061\n",
      "Epoch 43/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 9.4682e-04 - val_loss: 0.0061\n",
      "Epoch 44/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 9.4968e-04 - val_loss: 0.0060\n",
      "Epoch 45/300\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 9.3862e-04 - val_loss: 0.0060\n",
      "Epoch 46/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 9.4426e-04 - val_loss: 0.0060\n",
      "Epoch 47/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 9.3085e-04 - val_loss: 0.0060\n",
      "Epoch 48/300\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 9.4017e-04 - val_loss: 0.0059\n",
      "Epoch 49/300\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 9.2422e-04 - val_loss: 0.0059\n",
      "Epoch 50/300\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 9.3804e-04 - val_loss: 0.0058\n",
      "Epoch 51/300\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 9.2007e-04 - val_loss: 0.0058\n",
      "Epoch 52/300\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 9.3847e-04 - val_loss: 0.0057\n",
      "Epoch 53/300\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 9.2064e-04 - val_loss: 0.0057\n",
      "Epoch 54/300\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 9.4109e-04 - val_loss: 0.0057\n",
      "Epoch 55/300\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 9.2829e-04 - val_loss: 0.0056\n",
      "Epoch 56/300\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 9.4297e-04 - val_loss: 0.0056\n",
      "Epoch 57/300\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 9.4202e-04 - val_loss: 0.0054\n",
      "Epoch 58/300\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 9.3820e-04 - val_loss: 0.0055\n",
      "Epoch 59/300\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 9.5091e-04 - val_loss: 0.0051\n",
      "Epoch 60/300\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 9.2176e-04 - val_loss: 0.0055\n",
      "Epoch 61/300\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 9.3783e-04 - val_loss: 0.0050\n",
      "Epoch 62/300\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 8.9669e-04 - val_loss: 0.0054\n",
      "Epoch 63/300\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 9.0632e-04 - val_loss: 0.0049\n",
      "Epoch 64/300\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 8.7392e-04 - val_loss: 0.0053\n",
      "Epoch 65/300\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 8.7866e-04 - val_loss: 0.0049\n",
      "Epoch 66/300\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 8.5978e-04 - val_loss: 0.0052\n",
      "Epoch 67/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 8.6248e-04 - val_loss: 0.0050\n",
      "Epoch 68/300\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 8.5237e-04 - val_loss: 0.0051\n",
      "Epoch 69/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 8.5364e-04 - val_loss: 0.0050\n",
      "Epoch 70/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 8.4785e-04 - val_loss: 0.0051\n",
      "Epoch 71/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 8.4800e-04 - val_loss: 0.0050\n",
      "Epoch 72/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 8.4419e-04 - val_loss: 0.0050\n",
      "Epoch 73/300\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 8.4358e-04 - val_loss: 0.0050\n",
      "Epoch 74/300\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 8.4070e-04 - val_loss: 0.0050\n",
      "Epoch 75/300\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.3963e-04 - val_loss: 0.0049\n",
      "Epoch 76/300\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.3721e-04 - val_loss: 0.0049\n",
      "Epoch 77/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 8.3587e-04 - val_loss: 0.0049\n",
      "Epoch 78/300\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.3377e-04 - val_loss: 0.0049\n",
      "Epoch 79/300\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.3253e-04 - val_loss: 0.0049\n",
      "Epoch 80/300\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.3122e-04 - val_loss: 0.0049\n",
      "Epoch 81/300\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.2982e-04 - val_loss: 0.0049\n",
      "Epoch 82/300\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 8.2697e-04 - val_loss: 0.0049\n",
      "Epoch 83/300\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.2482e-04 - val_loss: 0.0048\n",
      "Epoch 84/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 8.2284e-04 - val_loss: 0.0048\n",
      "Epoch 85/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 8.2108e-04 - val_loss: 0.0048\n",
      "Epoch 86/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 8.1920e-04 - val_loss: 0.0048\n",
      "Epoch 87/300\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.1748e-04 - val_loss: 0.0048\n",
      "Epoch 88/300\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.1577e-04 - val_loss: 0.0047\n",
      "Epoch 89/300\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.1449e-04 - val_loss: 0.0047\n",
      "Epoch 90/300\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.1455e-04 - val_loss: 0.0047\n",
      "Epoch 91/300\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 8.1625e-04 - val_loss: 0.0047\n",
      "Epoch 92/300\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 8.1812e-04 - val_loss: 0.0046\n",
      "Epoch 93/300\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.1581e-04 - val_loss: 0.0046\n",
      "Epoch 94/300\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.0825e-04 - val_loss: 0.0047\n",
      "Epoch 95/300\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.0429e-04 - val_loss: 0.0047\n",
      "Epoch 96/300\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.0258e-04 - val_loss: 0.0046\n",
      "Epoch 97/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 8.0083e-04 - val_loss: 0.0046\n",
      "Epoch 98/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 7.9842e-04 - val_loss: 0.0046\n",
      "Epoch 99/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 7.9635e-04 - val_loss: 0.0046\n",
      "Epoch 100/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 7.9472e-04 - val_loss: 0.0045\n",
      "Epoch 101/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 7.9388e-04 - val_loss: 0.0045\n",
      "Epoch 102/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 7.9359e-04 - val_loss: 0.0045\n",
      "Epoch 103/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 7.9424e-04 - val_loss: 0.0045\n",
      "Epoch 104/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 7.9701e-04 - val_loss: 0.0044\n",
      "Epoch 105/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 7.9811e-04 - val_loss: 0.0044\n",
      "Epoch 106/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 7.9353e-04 - val_loss: 0.0044\n",
      "Epoch 107/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 7.8972e-04 - val_loss: 0.0044\n",
      "Epoch 108/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 7.8548e-04 - val_loss: 0.0044\n",
      "Epoch 109/300\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 7.8072e-04 - val_loss: 0.0044\n",
      "Epoch 110/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 7.7795e-04 - val_loss: 0.0044\n",
      "Epoch 111/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 7.7610e-04 - val_loss: 0.0044\n",
      "Epoch 112/300\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 7.7492e-04 - val_loss: 0.0043\n",
      "Epoch 113/300\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 7.7388e-04 - val_loss: 0.0043\n",
      "Epoch 114/300\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 7.7407e-04 - val_loss: 0.0043\n",
      "Epoch 115/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 7.7604e-04 - val_loss: 0.0043\n",
      "Epoch 116/300\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.7844e-04 - val_loss: 0.0042\n",
      "Epoch 117/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 7.7986e-04 - val_loss: 0.0042\n",
      "Epoch 118/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 7.7822e-04 - val_loss: 0.0042\n",
      "Epoch 119/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 7.7475e-04 - val_loss: 0.0042\n",
      "Epoch 120/300\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 7.6921e-04 - val_loss: 0.0042\n",
      "Epoch 121/300\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 7.6340e-04 - val_loss: 0.0042\n",
      "Epoch 122/300\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 7.5980e-04 - val_loss: 0.0042\n",
      "Epoch 123/300\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 7.5810e-04 - val_loss: 0.0042\n",
      "Epoch 124/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 7.5625e-04 - val_loss: 0.0041\n",
      "Epoch 125/300\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 7.5516e-04 - val_loss: 0.0041\n",
      "Epoch 126/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 7.5408e-04 - val_loss: 0.0041\n",
      "Epoch 127/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 7.5414e-04 - val_loss: 0.0041\n",
      "Epoch 128/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 7.5433e-04 - val_loss: 0.0040\n",
      "Epoch 129/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 7.5450e-04 - val_loss: 0.0040\n",
      "Epoch 130/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 7.5306e-04 - val_loss: 0.0040\n",
      "Epoch 131/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 7.5046e-04 - val_loss: 0.0040\n",
      "Epoch 132/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 7.4847e-04 - val_loss: 0.0040\n",
      "Epoch 133/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 7.4803e-04 - val_loss: 0.0040\n",
      "Epoch 134/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 7.5090e-04 - val_loss: 0.0039\n",
      "Epoch 135/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 7.5741e-04 - val_loss: 0.0039\n",
      "Epoch 136/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 7.6378e-04 - val_loss: 0.0038\n",
      "Epoch 137/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 7.7785e-04 - val_loss: 0.0038\n",
      "Epoch 138/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 7.9580e-04 - val_loss: 0.0036\n",
      "Epoch 139/300\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.1706e-04 - val_loss: 0.0035\n",
      "Epoch 140/300\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 8.5208e-04 - val_loss: 0.0033\n",
      "Epoch 141/300\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.9458e-04 - val_loss: 0.0033\n",
      "Epoch 142/300\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.9677e-04 - val_loss: 0.0036\n",
      "Epoch 143/300\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 8.6033e-04 - val_loss: 0.0035\n",
      "Epoch 144/300\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.9720e-04 - val_loss: 0.0039\n",
      "Epoch 145/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 7.6020e-04 - val_loss: 0.0043\n",
      "Epoch 146/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 7.2937e-04 - val_loss: 0.0041\n",
      "Epoch 147/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 7.2773e-04 - val_loss: 0.0041\n",
      "Epoch 148/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 7.2393e-04 - val_loss: 0.0040\n",
      "Epoch 149/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 7.2269e-04 - val_loss: 0.0040\n",
      "Epoch 150/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 7.2095e-04 - val_loss: 0.0039\n",
      "Epoch 151/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 7.1979e-04 - val_loss: 0.0039\n",
      "Epoch 152/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 7.1845e-04 - val_loss: 0.0039\n",
      "Epoch 153/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 7.1753e-04 - val_loss: 0.0038\n",
      "Epoch 154/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 7.1633e-04 - val_loss: 0.0038\n",
      "Epoch 155/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 7.1562e-04 - val_loss: 0.0038\n",
      "Epoch 156/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 7.1453e-04 - val_loss: 0.0037\n",
      "Epoch 157/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 7.1396e-04 - val_loss: 0.0037\n",
      "Epoch 158/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 7.1297e-04 - val_loss: 0.0037\n",
      "Epoch 159/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 7.1250e-04 - val_loss: 0.0037\n",
      "Epoch 160/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 7.1161e-04 - val_loss: 0.0036\n",
      "Epoch 161/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 7.1120e-04 - val_loss: 0.0036\n",
      "Epoch 162/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 7.1041e-04 - val_loss: 0.0036\n",
      "Epoch 163/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 7.1003e-04 - val_loss: 0.0036\n",
      "Epoch 164/300\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.0932e-04 - val_loss: 0.0036e\n",
      "Epoch 165/300\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 7.0897e-04 - val_loss: 0.0036\n",
      "Epoch 166/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 7.0834e-04 - val_loss: 0.0035\n",
      "Epoch 167/300\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.0799e-04 - val_loss: 0.0035\n",
      "Epoch 168/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 7.0744e-04 - val_loss: 0.0035\n",
      "Epoch 169/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 7.0710e-04 - val_loss: 0.0035\n",
      "Epoch 170/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 7.0660e-04 - val_loss: 0.0035\n",
      "Epoch 171/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 7.0627e-04 - val_loss: 0.0035\n",
      "Epoch 172/300\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 7.0583e-04 - val_loss: 0.0035\n",
      "Epoch 173/300\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.0551e-04 - val_loss: 0.0035\n",
      "Epoch 174/300\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 7.0512e-04 - val_loss: 0.0035\n",
      "Epoch 175/300\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 7.0483e-04 - val_loss: 0.0034\n",
      "Epoch 176/300\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 7.0455e-04 - val_loss: 0.0034\n",
      "Epoch 177/300\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.0447e-04 - val_loss: 0.0034\n",
      "Epoch 178/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 7.0472e-04 - val_loss: 0.0034\n",
      "Epoch 179/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 7.0538e-04 - val_loss: 0.0034\n",
      "Epoch 180/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 7.0521e-04 - val_loss: 0.0034\n",
      "Epoch 181/300\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 7.0433e-04 - val_loss: 0.0034\n",
      "Epoch 182/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 7.0478e-04 - val_loss: 0.0034\n",
      "Epoch 183/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 7.0576e-04 - val_loss: 0.0034\n",
      "Epoch 184/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 7.0534e-04 - val_loss: 0.0034\n",
      "Epoch 185/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 7.0391e-04 - val_loss: 0.0034\n",
      "Epoch 186/300\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 7.0276e-04 - val_loss: 0.0034\n",
      "Epoch 187/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 7.0230e-04 - val_loss: 0.0034\n",
      "Epoch 188/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 7.0211e-04 - val_loss: 0.0034\n",
      "Epoch 189/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 7.0205e-04 - val_loss: 0.0034\n",
      "Epoch 190/300\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.0245e-04 - val_loss: 0.0034\n",
      "Epoch 191/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 7.0294e-04 - val_loss: 0.0034\n",
      "Epoch 192/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 7.0441e-04 - val_loss: 0.0034\n",
      "Epoch 193/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 7.0705e-04 - val_loss: 0.0034\n",
      "Epoch 194/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 7.0768e-04 - val_loss: 0.0033\n",
      "Epoch 195/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 7.0621e-04 - val_loss: 0.0034\n",
      "Epoch 196/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 7.0395e-04 - val_loss: 0.0034\n",
      "Epoch 197/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 7.0224e-04 - val_loss: 0.0034\n",
      "Epoch 198/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 6.9995e-04 - val_loss: 0.0034\n",
      "Epoch 199/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 6.9956e-04 - val_loss: 0.0034\n",
      "Epoch 200/300\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 6.9937e-04 - val_loss: 0.0034\n",
      "Epoch 201/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 7.0040e-04 - val_loss: 0.0034\n",
      "Epoch 202/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 7.0162e-04 - val_loss: 0.0034\n",
      "Epoch 203/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 7.0373e-04 - val_loss: 0.0033\n",
      "Epoch 204/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 7.0475e-04 - val_loss: 0.0033\n",
      "Epoch 205/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 7.0516e-04 - val_loss: 0.0033\n",
      "Epoch 206/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 7.0566e-04 - val_loss: 0.0033\n",
      "Epoch 207/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 7.0333e-04 - val_loss: 0.0033\n",
      "Epoch 208/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 6.9972e-04 - val_loss: 0.0034\n",
      "Epoch 209/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 6.9687e-04 - val_loss: 0.0034\n",
      "Epoch 210/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 6.9590e-04 - val_loss: 0.0034\n",
      "Epoch 211/300\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 6.9547e-04 - val_loss: 0.0034\n",
      "Epoch 212/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 6.9574e-04 - val_loss: 0.0034\n",
      "Epoch 213/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 6.9576e-04 - val_loss: 0.0033\n",
      "Epoch 214/300\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 6.9612e-04 - val_loss: 0.0033\n",
      "Epoch 215/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 6.9681e-04 - val_loss: 0.0033\n",
      "Epoch 216/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 6.9885e-04 - val_loss: 0.0033\n",
      "Epoch 217/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 6.9975e-04 - val_loss: 0.0033\n",
      "Epoch 218/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 7.0034e-04 - val_loss: 0.0033\n",
      "Epoch 219/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 7.0132e-04 - val_loss: 0.0033\n",
      "Epoch 220/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 6.9953e-04 - val_loss: 0.0033e-0\n",
      "Epoch 221/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 6.9739e-04 - val_loss: 0.0033\n",
      "Epoch 222/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 6.9761e-04 - val_loss: 0.0033\n",
      "Epoch 223/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 6.9819e-04 - val_loss: 0.0033\n",
      "Epoch 224/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 6.9682e-04 - val_loss: 0.0033\n",
      "Epoch 225/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 6.9602e-04 - val_loss: 0.0033\n",
      "Epoch 226/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 6.9556e-04 - val_loss: 0.0033\n",
      "Epoch 227/300\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 6.9544e-04 - val_loss: 0.0033\n",
      "Epoch 228/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 6.9666e-04 - val_loss: 0.0033\n",
      "Epoch 229/300\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 6.9661e-04 - val_loss: 0.0033\n",
      "Epoch 230/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 6.9545e-04 - val_loss: 0.0033\n",
      "Epoch 231/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 6.9396e-04 - val_loss: 0.0033\n",
      "Epoch 232/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 6.9310e-04 - val_loss: 0.0033\n",
      "Epoch 233/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 6.9267e-04 - val_loss: 0.0033\n",
      "Epoch 234/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 6.9334e-04 - val_loss: 0.0033\n",
      "Epoch 235/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 6.9604e-04 - val_loss: 0.0033\n",
      "Epoch 236/300\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 7.0004e-04 - val_loss: 0.0033\n",
      "Epoch 237/300\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 6.9853e-04 - val_loss: 0.0033\n",
      "Epoch 238/300\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 6.9842e-04 - val_loss: 0.0033\n",
      "Epoch 239/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 6.9753e-04 - val_loss: 0.0033\n",
      "Epoch 240/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 6.9583e-04 - val_loss: 0.0033\n",
      "Epoch 241/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 6.9491e-04 - val_loss: 0.0033e-\n",
      "Epoch 242/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 6.9251e-04 - val_loss: 0.0033\n",
      "Epoch 243/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 6.9082e-04 - val_loss: 0.0033\n",
      "Epoch 244/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 6.8948e-04 - val_loss: 0.0033\n",
      "Epoch 245/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 6.8865e-04 - val_loss: 0.0033\n",
      "Epoch 246/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 6.8874e-04 - val_loss: 0.0033\n",
      "Epoch 247/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 6.8883e-04 - val_loss: 0.0033\n",
      "Epoch 248/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 6.8973e-04 - val_loss: 0.0033\n",
      "Epoch 249/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 6.8993e-04 - val_loss: 0.0033\n",
      "Epoch 250/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 6.8950e-04 - val_loss: 0.0033\n",
      "Epoch 251/300\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 6.8886e-04 - val_loss: 0.0033\n",
      "Epoch 252/300\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 6.8944e-04 - val_loss: 0.0033\n",
      "Epoch 253/300\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 6.9030e-04 - val_loss: 0.0033\n",
      "Epoch 254/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 6.9187e-04 - val_loss: 0.0033\n",
      "Epoch 255/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 6.9353e-04 - val_loss: 0.0033\n",
      "Epoch 256/300\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 6.9674e-04 - val_loss: 0.0033\n",
      "Epoch 257/300\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 7.0506e-04 - val_loss: 0.0033\n",
      "Epoch 258/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 7.1660e-04 - val_loss: 0.0032\n",
      "Epoch 259/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 7.3855e-04 - val_loss: 0.0031\n",
      "Epoch 260/300\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 7.6414e-04 - val_loss: 0.0029\n",
      "Epoch 261/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 8.0894e-04 - val_loss: 0.0028\n",
      "Epoch 262/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 8.4966e-04 - val_loss: 0.0032\n",
      "Epoch 263/300\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.0452e-04 - val_loss: 0.0032\n",
      "Epoch 264/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 8.2482e-04 - val_loss: 0.0029\n",
      "Epoch 265/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 7.6800e-04 - val_loss: 0.0033\n",
      "Epoch 266/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 7.1447e-04 - val_loss: 0.0037\n",
      "Epoch 267/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 6.9336e-04 - val_loss: 0.0036\n",
      "Epoch 268/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 7.0135e-04 - val_loss: 0.0035\n",
      "Epoch 269/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 7.0484e-04 - val_loss: 0.0036\n",
      "Epoch 270/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 7.1397e-04 - val_loss: 0.0033\n",
      "Epoch 271/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 7.0666e-04 - val_loss: 0.0034\n",
      "Epoch 272/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 7.0253e-04 - val_loss: 0.0033\n",
      "Epoch 273/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 6.9329e-04 - val_loss: 0.0033\n",
      "Epoch 274/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 6.9522e-04 - val_loss: 0.0033\n",
      "Epoch 275/300\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 6.8789e-04 - val_loss: 0.0033\n",
      "Epoch 276/300\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 6.9085e-04 - val_loss: 0.0033\n",
      "Epoch 277/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 6.8449e-04 - val_loss: 0.0033\n",
      "Epoch 278/300\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 6.8714e-04 - val_loss: 0.0033\n",
      "Epoch 279/300\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 6.8200e-04 - val_loss: 0.0032\n",
      "Epoch 280/300\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 6.8512e-04 - val_loss: 0.0033\n",
      "Epoch 281/300\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 6.8078e-04 - val_loss: 0.0032\n",
      "Epoch 282/300\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 6.8396e-04 - val_loss: 0.0032\n",
      "Epoch 283/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 6.8014e-04 - val_loss: 0.0032\n",
      "Epoch 284/300\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 6.8310e-04 - val_loss: 0.0032\n",
      "Epoch 285/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 6.7969e-04 - val_loss: 0.0032\n",
      "Epoch 286/300\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 6.8240e-04 - val_loss: 0.0032\n",
      "Epoch 287/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 6.7938e-04 - val_loss: 0.0032\n",
      "Epoch 288/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 6.8184e-04 - val_loss: 0.0032\n",
      "Epoch 289/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 6.7918e-04 - val_loss: 0.0032\n",
      "Epoch 290/300\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 6.8142e-04 - val_loss: 0.0032\n",
      "Epoch 291/300\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 6.7908e-04 - val_loss: 0.0032\n",
      "Epoch 292/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 6.8107e-04 - val_loss: 0.0032\n",
      "Epoch 293/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 6.7901e-04 - val_loss: 0.0032\n",
      "Epoch 294/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 6.8074e-04 - val_loss: 0.0032\n",
      "Epoch 295/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 6.7893e-04 - val_loss: 0.0032\n",
      "Epoch 296/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 6.8039e-04 - val_loss: 0.0032\n",
      "Epoch 297/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 6.7881e-04 - val_loss: 0.0032\n",
      "Epoch 298/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 6.8004e-04 - val_loss: 0.0032\n",
      "Epoch 299/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 6.7868e-04 - val_loss: 0.0032\n",
      "Epoch 300/300\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 6.7973e-04 - val_loss: 0.0032\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(256, input_shape=(7,1)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1],1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1],1))\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=300,\n",
    "    validation_data = (X_test, y_test),\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Xt = model.predict(X_test)\n",
    "\n",
    "plt.plot(scl.inverse_transform(y_test.reshape(-1,1)), label = 'actual')\n",
    "plt.plot(scl.inverse_transform(Xt), label='predict')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np \n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    .,   .,     \n",
      "  : 12\n",
      "{'': 1, '': 2, '': 3, '': 4, '': 5, '': 6, '': 7, '': 8, '': 9, '': 10, '': 11}\n"
     ]
    }
   ],
   "source": [
    "text = \"    .,   .,     \"\n",
    "\n",
    "t = Tokenizer()\n",
    "print(text)\n",
    "t.fit_on_texts([text])\n",
    "vocab_size = len(t.word_index) + 1\n",
    "\n",
    "print('  : %d' % vocab_size)\n",
    "print(t.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   : 11\n",
      "   : 6\n"
     ]
    }
   ],
   "source": [
    "sequences = list()\n",
    "for line in text.split(',') :\n",
    "    encoded = t.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(encoded)):\n",
    "        sequence = encoded[:i+1]\n",
    "        sequences.append(sequence)\n",
    "        \n",
    "print('   : %d' % len(sequences))\n",
    "\n",
    "max_len = max(len(l) for l in sequences)\n",
    "print('   : {}'.format(max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  2  3]\n",
      " [ 0  0  0  2  3  1]\n",
      " [ 0  0  2  3  1  4]\n",
      " [ 0  2  3  1  4  5]\n",
      " [ 0  0  0  0  6  1]\n",
      " [ 0  0  0  6  1  7]\n",
      " [ 0  0  0  0  8  1]\n",
      " [ 0  0  0  8  1  9]\n",
      " [ 0  0  8  1  9 10]\n",
      " [ 0  8  1  9 10  1]\n",
      " [ 8  1  9 10  1 11]]\n"
     ]
    }
   ],
   "source": [
    "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')\n",
    "\n",
    "print(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  2]\n",
      " [ 0  0  0  2  3]\n",
      " [ 0  0  2  3  1]\n",
      " [ 0  2  3  1  4]\n",
      " [ 0  0  0  0  6]\n",
      " [ 0  0  0  6  1]\n",
      " [ 0  0  0  0  8]\n",
      " [ 0  0  0  8  1]\n",
      " [ 0  0  8  1  9]\n",
      " [ 0  8  1  9 10]\n",
      " [ 8  1  9 10  1]]\n"
     ]
    }
   ],
   "source": [
    "sequences = np.array(sequences)\n",
    "X = sequences[:,:-1]\n",
    "y = sequences[:,-1]\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 - 0s - loss: 2.5105 - accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 2.4961 - accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 2.4819 - accuracy: 0.0909\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 2.4676 - accuracy: 0.1818\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 2.4532 - accuracy: 0.1818\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 2.4386 - accuracy: 0.3636\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 2.4236 - accuracy: 0.3636\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 2.4083 - accuracy: 0.3636\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 2.3924 - accuracy: 0.3636\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 2.3761 - accuracy: 0.3636\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 2.3591 - accuracy: 0.3636\n",
      "Epoch 12/200\n",
      "1/1 - 0s - loss: 2.3415 - accuracy: 0.3636\n",
      "Epoch 13/200\n",
      "1/1 - 0s - loss: 2.3233 - accuracy: 0.3636\n",
      "Epoch 14/200\n",
      "1/1 - 0s - loss: 2.3043 - accuracy: 0.3636\n",
      "Epoch 15/200\n",
      "1/1 - 0s - loss: 2.2846 - accuracy: 0.3636\n",
      "Epoch 16/200\n",
      "1/1 - 0s - loss: 2.2641 - accuracy: 0.3636\n",
      "Epoch 17/200\n",
      "1/1 - 0s - loss: 2.2429 - accuracy: 0.3636\n",
      "Epoch 18/200\n",
      "1/1 - 0s - loss: 2.2211 - accuracy: 0.3636\n",
      "Epoch 19/200\n",
      "1/1 - 0s - loss: 2.1985 - accuracy: 0.3636\n",
      "Epoch 20/200\n",
      "1/1 - 0s - loss: 2.1755 - accuracy: 0.3636\n",
      "Epoch 21/200\n",
      "1/1 - 0s - loss: 2.1519 - accuracy: 0.3636\n",
      "Epoch 22/200\n",
      "1/1 - 0s - loss: 2.1281 - accuracy: 0.3636\n",
      "Epoch 23/200\n",
      "1/1 - 0s - loss: 2.1041 - accuracy: 0.3636\n",
      "Epoch 24/200\n",
      "1/1 - 0s - loss: 2.0803 - accuracy: 0.3636\n",
      "Epoch 25/200\n",
      "1/1 - 0s - loss: 2.0567 - accuracy: 0.3636\n",
      "Epoch 26/200\n",
      "1/1 - 0s - loss: 2.0337 - accuracy: 0.3636\n",
      "Epoch 27/200\n",
      "1/1 - 0s - loss: 2.0114 - accuracy: 0.3636\n",
      "Epoch 28/200\n",
      "1/1 - 0s - loss: 1.9901 - accuracy: 0.3636\n",
      "Epoch 29/200\n",
      "1/1 - 0s - loss: 1.9700 - accuracy: 0.3636\n",
      "Epoch 30/200\n",
      "1/1 - 0s - loss: 1.9511 - accuracy: 0.3636\n",
      "Epoch 31/200\n",
      "1/1 - 0s - loss: 1.9333 - accuracy: 0.3636\n",
      "Epoch 32/200\n",
      "1/1 - 0s - loss: 1.9164 - accuracy: 0.3636\n",
      "Epoch 33/200\n",
      "1/1 - 0s - loss: 1.9003 - accuracy: 0.3636\n",
      "Epoch 34/200\n",
      "1/1 - 0s - loss: 1.8845 - accuracy: 0.3636\n",
      "Epoch 35/200\n",
      "1/1 - 0s - loss: 1.8688 - accuracy: 0.3636\n",
      "Epoch 36/200\n",
      "1/1 - 0s - loss: 1.8528 - accuracy: 0.3636\n",
      "Epoch 37/200\n",
      "1/1 - 0s - loss: 1.8364 - accuracy: 0.3636\n",
      "Epoch 38/200\n",
      "1/1 - 0s - loss: 1.8195 - accuracy: 0.3636\n",
      "Epoch 39/200\n",
      "1/1 - 0s - loss: 1.8020 - accuracy: 0.3636\n",
      "Epoch 40/200\n",
      "1/1 - 0s - loss: 1.7840 - accuracy: 0.3636\n",
      "Epoch 41/200\n",
      "1/1 - 0s - loss: 1.7658 - accuracy: 0.3636\n",
      "Epoch 42/200\n",
      "1/1 - 0s - loss: 1.7474 - accuracy: 0.4545\n",
      "Epoch 43/200\n",
      "1/1 - 0s - loss: 1.7290 - accuracy: 0.4545\n",
      "Epoch 44/200\n",
      "1/1 - 0s - loss: 1.7107 - accuracy: 0.4545\n",
      "Epoch 45/200\n",
      "1/1 - 0s - loss: 1.6927 - accuracy: 0.4545\n",
      "Epoch 46/200\n",
      "1/1 - 0s - loss: 1.6749 - accuracy: 0.4545\n",
      "Epoch 47/200\n",
      "1/1 - 0s - loss: 1.6572 - accuracy: 0.4545\n",
      "Epoch 48/200\n",
      "1/1 - 0s - loss: 1.6398 - accuracy: 0.4545\n",
      "Epoch 49/200\n",
      "1/1 - 0s - loss: 1.6224 - accuracy: 0.4545\n",
      "Epoch 50/200\n",
      "1/1 - 0s - loss: 1.6050 - accuracy: 0.4545\n",
      "Epoch 51/200\n",
      "1/1 - 0s - loss: 1.5875 - accuracy: 0.4545\n",
      "Epoch 52/200\n",
      "1/1 - 0s - loss: 1.5700 - accuracy: 0.4545\n",
      "Epoch 53/200\n",
      "1/1 - 0s - loss: 1.5524 - accuracy: 0.4545\n",
      "Epoch 54/200\n",
      "1/1 - 0s - loss: 1.5347 - accuracy: 0.4545\n",
      "Epoch 55/200\n",
      "1/1 - 0s - loss: 1.5170 - accuracy: 0.4545\n",
      "Epoch 56/200\n",
      "1/1 - 0s - loss: 1.4993 - accuracy: 0.4545\n",
      "Epoch 57/200\n",
      "1/1 - 0s - loss: 1.4817 - accuracy: 0.5455\n",
      "Epoch 58/200\n",
      "1/1 - 0s - loss: 1.4643 - accuracy: 0.5455\n",
      "Epoch 59/200\n",
      "1/1 - 0s - loss: 1.4470 - accuracy: 0.5455\n",
      "Epoch 60/200\n",
      "1/1 - 0s - loss: 1.4300 - accuracy: 0.5455\n",
      "Epoch 61/200\n",
      "1/1 - 0s - loss: 1.4131 - accuracy: 0.5455\n",
      "Epoch 62/200\n",
      "1/1 - 0s - loss: 1.3965 - accuracy: 0.5455\n",
      "Epoch 63/200\n",
      "1/1 - 0s - loss: 1.3801 - accuracy: 0.5455\n",
      "Epoch 64/200\n",
      "1/1 - 0s - loss: 1.3639 - accuracy: 0.5455\n",
      "Epoch 65/200\n",
      "1/1 - 0s - loss: 1.3478 - accuracy: 0.5455\n",
      "Epoch 66/200\n",
      "1/1 - 0s - loss: 1.3318 - accuracy: 0.5455\n",
      "Epoch 67/200\n",
      "1/1 - 0s - loss: 1.3158 - accuracy: 0.5455\n",
      "Epoch 68/200\n",
      "1/1 - 0s - loss: 1.2999 - accuracy: 0.5455\n",
      "Epoch 69/200\n",
      "1/1 - 0s - loss: 1.2841 - accuracy: 0.5455\n",
      "Epoch 70/200\n",
      "1/1 - 0s - loss: 1.2682 - accuracy: 0.5455\n",
      "Epoch 71/200\n",
      "1/1 - 0s - loss: 1.2524 - accuracy: 0.5455\n",
      "Epoch 72/200\n",
      "1/1 - 0s - loss: 1.2366 - accuracy: 0.5455\n",
      "Epoch 73/200\n",
      "1/1 - 0s - loss: 1.2208 - accuracy: 0.5455\n",
      "Epoch 74/200\n",
      "1/1 - 0s - loss: 1.2050 - accuracy: 0.5455\n",
      "Epoch 75/200\n",
      "1/1 - 0s - loss: 1.1892 - accuracy: 0.5455\n",
      "Epoch 76/200\n",
      "1/1 - 0s - loss: 1.1734 - accuracy: 0.5455\n",
      "Epoch 77/200\n",
      "1/1 - 0s - loss: 1.1575 - accuracy: 0.5455\n",
      "Epoch 78/200\n",
      "1/1 - 0s - loss: 1.1416 - accuracy: 0.5455\n",
      "Epoch 79/200\n",
      "1/1 - 0s - loss: 1.1257 - accuracy: 0.5455\n",
      "Epoch 80/200\n",
      "1/1 - 0s - loss: 1.1098 - accuracy: 0.5455\n",
      "Epoch 81/200\n",
      "1/1 - 0s - loss: 1.0938 - accuracy: 0.5455\n",
      "Epoch 82/200\n",
      "1/1 - 0s - loss: 1.0778 - accuracy: 0.5455\n",
      "Epoch 83/200\n",
      "1/1 - 0s - loss: 1.0617 - accuracy: 0.5455\n",
      "Epoch 84/200\n",
      "1/1 - 0s - loss: 1.0456 - accuracy: 0.5455\n",
      "Epoch 85/200\n",
      "1/1 - 0s - loss: 1.0295 - accuracy: 0.5455\n",
      "Epoch 86/200\n",
      "1/1 - 0s - loss: 1.0133 - accuracy: 0.5455\n",
      "Epoch 87/200\n",
      "1/1 - 0s - loss: 0.9971 - accuracy: 0.5455\n",
      "Epoch 88/200\n",
      "1/1 - 0s - loss: 0.9808 - accuracy: 0.5455\n",
      "Epoch 89/200\n",
      "1/1 - 0s - loss: 0.9646 - accuracy: 0.5455\n",
      "Epoch 90/200\n",
      "1/1 - 0s - loss: 0.9483 - accuracy: 0.5455\n",
      "Epoch 91/200\n",
      "1/1 - 0s - loss: 0.9320 - accuracy: 0.7273\n",
      "Epoch 92/200\n",
      "1/1 - 0s - loss: 0.9156 - accuracy: 0.8182\n",
      "Epoch 93/200\n",
      "1/1 - 0s - loss: 0.8993 - accuracy: 0.8182\n",
      "Epoch 94/200\n",
      "1/1 - 0s - loss: 0.8830 - accuracy: 0.8182\n",
      "Epoch 95/200\n",
      "1/1 - 0s - loss: 0.8667 - accuracy: 0.8182\n",
      "Epoch 96/200\n",
      "1/1 - 0s - loss: 0.8505 - accuracy: 0.8182\n",
      "Epoch 97/200\n",
      "1/1 - 0s - loss: 0.8343 - accuracy: 0.8182\n",
      "Epoch 98/200\n",
      "1/1 - 0s - loss: 0.8182 - accuracy: 0.8182\n",
      "Epoch 99/200\n",
      "1/1 - 0s - loss: 0.8021 - accuracy: 0.8182\n",
      "Epoch 100/200\n",
      "1/1 - 0s - loss: 0.7862 - accuracy: 0.8182\n",
      "Epoch 101/200\n",
      "1/1 - 0s - loss: 0.7703 - accuracy: 0.9091\n",
      "Epoch 102/200\n",
      "1/1 - 0s - loss: 0.7546 - accuracy: 0.9091\n",
      "Epoch 103/200\n",
      "1/1 - 0s - loss: 0.7390 - accuracy: 0.9091\n",
      "Epoch 104/200\n",
      "1/1 - 0s - loss: 0.7236 - accuracy: 0.9091\n",
      "Epoch 105/200\n",
      "1/1 - 0s - loss: 0.7083 - accuracy: 0.9091\n",
      "Epoch 106/200\n",
      "1/1 - 0s - loss: 0.6933 - accuracy: 0.9091\n",
      "Epoch 107/200\n",
      "1/1 - 0s - loss: 0.6784 - accuracy: 0.9091\n",
      "Epoch 108/200\n",
      "1/1 - 0s - loss: 0.6637 - accuracy: 0.9091\n",
      "Epoch 109/200\n",
      "1/1 - 0s - loss: 0.6493 - accuracy: 0.9091\n",
      "Epoch 110/200\n",
      "1/1 - 0s - loss: 0.6351 - accuracy: 0.9091\n",
      "Epoch 111/200\n",
      "1/1 - 0s - loss: 0.6211 - accuracy: 0.9091\n",
      "Epoch 112/200\n",
      "1/1 - 0s - loss: 0.6074 - accuracy: 0.9091\n",
      "Epoch 113/200\n",
      "1/1 - 0s - loss: 0.5939 - accuracy: 0.9091\n",
      "Epoch 114/200\n",
      "1/1 - 0s - loss: 0.5807 - accuracy: 0.9091\n",
      "Epoch 115/200\n",
      "1/1 - 0s - loss: 0.5678 - accuracy: 0.9091\n",
      "Epoch 116/200\n",
      "1/1 - 0s - loss: 0.5551 - accuracy: 0.9091\n",
      "Epoch 117/200\n",
      "1/1 - 0s - loss: 0.5428 - accuracy: 0.9091\n",
      "Epoch 118/200\n",
      "1/1 - 0s - loss: 0.5306 - accuracy: 0.9091\n",
      "Epoch 119/200\n",
      "1/1 - 0s - loss: 0.5188 - accuracy: 0.9091\n",
      "Epoch 120/200\n",
      "1/1 - 0s - loss: 0.5072 - accuracy: 0.9091\n",
      "Epoch 121/200\n",
      "1/1 - 0s - loss: 0.4959 - accuracy: 0.9091\n",
      "Epoch 122/200\n",
      "1/1 - 0s - loss: 0.4849 - accuracy: 0.9091\n",
      "Epoch 123/200\n",
      "1/1 - 0s - loss: 0.4741 - accuracy: 0.9091\n",
      "Epoch 124/200\n",
      "1/1 - 0s - loss: 0.4636 - accuracy: 0.9091\n",
      "Epoch 125/200\n",
      "1/1 - 0s - loss: 0.4533 - accuracy: 0.9091\n",
      "Epoch 126/200\n",
      "1/1 - 0s - loss: 0.4433 - accuracy: 0.9091\n",
      "Epoch 127/200\n",
      "1/1 - 0s - loss: 0.4335 - accuracy: 0.9091\n",
      "Epoch 128/200\n",
      "1/1 - 0s - loss: 0.4240 - accuracy: 0.9091\n",
      "Epoch 129/200\n",
      "1/1 - 0s - loss: 0.4148 - accuracy: 0.9091\n",
      "Epoch 130/200\n",
      "1/1 - 0s - loss: 0.4057 - accuracy: 0.9091\n",
      "Epoch 131/200\n",
      "1/1 - 0s - loss: 0.3969 - accuracy: 0.9091\n",
      "Epoch 132/200\n",
      "1/1 - 0s - loss: 0.3883 - accuracy: 0.9091\n",
      "Epoch 133/200\n",
      "1/1 - 0s - loss: 0.3799 - accuracy: 0.9091\n",
      "Epoch 134/200\n",
      "1/1 - 0s - loss: 0.3718 - accuracy: 0.9091\n",
      "Epoch 135/200\n",
      "1/1 - 0s - loss: 0.3638 - accuracy: 0.9091\n",
      "Epoch 136/200\n",
      "1/1 - 0s - loss: 0.3560 - accuracy: 0.9091\n",
      "Epoch 137/200\n",
      "1/1 - 0s - loss: 0.3485 - accuracy: 0.9091\n",
      "Epoch 138/200\n",
      "1/1 - 0s - loss: 0.3411 - accuracy: 0.9091\n",
      "Epoch 139/200\n",
      "1/1 - 0s - loss: 0.3339 - accuracy: 0.9091\n",
      "Epoch 140/200\n",
      "1/1 - 0s - loss: 0.3268 - accuracy: 0.9091\n",
      "Epoch 141/200\n",
      "1/1 - 0s - loss: 0.3199 - accuracy: 0.9091\n",
      "Epoch 142/200\n",
      "1/1 - 0s - loss: 0.3132 - accuracy: 0.9091\n",
      "Epoch 143/200\n",
      "1/1 - 0s - loss: 0.3067 - accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "1/1 - 0s - loss: 0.3002 - accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "1/1 - 0s - loss: 0.2940 - accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "1/1 - 0s - loss: 0.2879 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "1/1 - 0s - loss: 0.2819 - accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "1/1 - 0s - loss: 0.2760 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "1/1 - 0s - loss: 0.2703 - accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "1/1 - 0s - loss: 0.2647 - accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "1/1 - 0s - loss: 0.2592 - accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "1/1 - 0s - loss: 0.2538 - accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "1/1 - 0s - loss: 0.2486 - accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "1/1 - 0s - loss: 0.2434 - accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "1/1 - 0s - loss: 0.2384 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "1/1 - 0s - loss: 0.2334 - accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "1/1 - 0s - loss: 0.2286 - accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "1/1 - 0s - loss: 0.2239 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "1/1 - 0s - loss: 0.2193 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "1/1 - 0s - loss: 0.2147 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "1/1 - 0s - loss: 0.2103 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "1/1 - 0s - loss: 0.2059 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "1/1 - 0s - loss: 0.2017 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "1/1 - 0s - loss: 0.1975 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "1/1 - 0s - loss: 0.1934 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "1/1 - 0s - loss: 0.1894 - accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "1/1 - 0s - loss: 0.1855 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "1/1 - 0s - loss: 0.1817 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "1/1 - 0s - loss: 0.1779 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "1/1 - 0s - loss: 0.1743 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "1/1 - 0s - loss: 0.1707 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "1/1 - 0s - loss: 0.1671 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "1/1 - 0s - loss: 0.1637 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "1/1 - 0s - loss: 0.1603 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "1/1 - 0s - loss: 0.1571 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "1/1 - 0s - loss: 0.1538 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "1/1 - 0s - loss: 0.1507 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "1/1 - 0s - loss: 0.1476 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "1/1 - 0s - loss: 0.1446 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "1/1 - 0s - loss: 0.1417 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "1/1 - 0s - loss: 0.1388 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "1/1 - 0s - loss: 0.1360 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "1/1 - 0s - loss: 0.1333 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "1/1 - 0s - loss: 0.1306 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "1/1 - 0s - loss: 0.1280 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "1/1 - 0s - loss: 0.1255 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "1/1 - 0s - loss: 0.1230 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "1/1 - 0s - loss: 0.1206 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "1/1 - 0s - loss: 0.1182 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "1/1 - 0s - loss: 0.1159 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "1/1 - 0s - loss: 0.1136 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "1/1 - 0s - loss: 0.1114 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "1/1 - 0s - loss: 0.1093 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "1/1 - 0s - loss: 0.1072 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "1/1 - 0s - loss: 0.1052 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "1/1 - 0s - loss: 0.1032 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "1/1 - 0s - loss: 0.1012 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "1/1 - 0s - loss: 0.0993 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "1/1 - 0s - loss: 0.0975 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "1/1 - 0s - loss: 0.0957 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c771805b08>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, SimpleRNN\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 10, input_length = max_len-1))\n",
    "\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(vocab_size, activation = 'softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "model.fit(X, y, epochs=200, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(model, t, current_word, n):\n",
    "    init_word = current_word\n",
    "    sentence = ' '\n",
    "    for _ in range(n):\n",
    "        encoded = t.texts_to_sequences([current_word])[0]\n",
    "        encoded = pad_sequences([encoded], maxlen=5, padding='pre')\n",
    "        result = model.predict_classes(encoded, verbose = 0)\n",
    "        for word, index in t.word_index.items():\n",
    "            if index == result:\n",
    "                break\n",
    "        current_word = current_word + ' ' + word\n",
    "        sentence = sentence + ' ' + word\n",
    "    sentence = init_word + sentence\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     \n",
      "   \n",
      "      \n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, t, '', 4))\n",
    "\n",
    "print(sentence_generation(model, t, '', 2))\n",
    "\n",
    "print(sentence_generation(model, t, '', 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
